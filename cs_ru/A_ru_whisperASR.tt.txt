6.51	7.31	Учитель.
29.72	31.08	Посмотрим, посмотрим.
32.44	46.68	Да, да, да, да, да.
116.3	116.76	Хорошо.
138.49	142.51	Хорошо, я вас еще раз поприветствую.
143.07	150.89	Здравствуйте, я __PERSON1__, и сейчас расскажу немного, чем я занимаюсь в рамках проекта
150.89	155.17	на предмете по статистическим методам перевода.
155.17	166.33	В проекте целью является натренировать систему для перевода с английского на русский язык
166.33	179.89	и в идеале еще написать статью об этом и отправить результаты системы на конференцию в МТ,
179.89	179.95	в МТ.
180.89	193.29	Поэтому сейчас такое техническое задание нуждается в небольшой проработке, наверное,
193.49	200.97	поэтому я решил, что нужно воспользоваться сразу консультацией в первом слоте.
200.97	209.67	И на самом деле мне очень сложно говорить об этом по-русски,
209.83	209.97	потому что никогда...
210.89	215.33	никогда ни с кем не говорю по-русски о программировании.
216.71	224.41	Я постараюсь немного увеличить темп речи, если это, конечно, не будет мешать системе.
225.15	234.27	И в данный момент я стараюсь перейти на другую библиотеку для тренировки.
234.27	240.33	Мы с __PERSON2__ подумали, посидели.
240.33	242.33	Очень много...
242.33	254.33	Очень много мы нашли различных вещей, где можно как-то улучшить нашу систему, наш подход.
254.99	260.39	И мы пришли к выводу, что, наверное, стоит попробовать библиотеку,
260.49	266.01	которая справляется с тренировкой на нескольких графических картах.
267.31	270.01	И поэтому я в выходные...
270.33	276.69	смотрел, как можно, во-первых, подготавливать данные для тренировки,
277.79	286.45	а потом я вот пытался как-то установить библиотеку другую,
286.45	297.45	но вообще она не работает, потому что, как обычно, в языке Python очень сложно...
298.29	299.45	эти библиотеки...
300.33	308.33	наконфигурировать правильно все вместе, чтобы они работали и не давали...
311.15	315.17	Ага, да.
316.25	320.77	__PERSON2__ использует Ansloth.
321.59	333.75	Это название библиотеки, которая как раз-таки занимается ускорением тренировочного процесса и эффективности памяти.
334.81	339.21	Но для обычных людей, которые не платят,
339.91	346.17	то есть открытая версия поддерживает улучшение тренировки только на одной графической карте.
346.77	352.69	И, как мне показалось, это очень большое упущение,
353.87	362.79	учитывая, что мы можем брать и на мета-центре, и на других кластерах мы можем брать, в принципе, больше GPU.
362.79	364.61	Почему бы это не использовать?
364.81	365.81	Да.
365.81	376.83	И мы с __PERSON2__ договорились, что мы перейдем на библиотеку другую.
376.83	382.83	И в итоге я начал пробовать играться с Axolotl.
382.83	394.83	Axolotl — это библиотека, которая тоже интегрирует какие-то определенные улучшения с уже перечисленной библиотекой.
394.83	395.83	Но...
395.83	396.83	Да.
396.83	403.83	Там есть и поддержка нескольких графических карт и достаточно богатая конфигурация.
404.83	411.11	Но, опять же, я вот сидел целый день, и оно у меня выдавало ошибку,
411.25	419.75	что там какая-то операция не поддерживается для данного типа.
419.75	426.75	То есть там был тип bfloat16, и почему-то какая-то функция для него...
426.83	427.83	Не наимплементирована.
427.83	436.83	И, значит, мы с __PERSON2__ быстро покорреспондировали по поводу данной ошибки.
436.83	447.83	И сейчас стараемся установить, как бы, как лучше установить библиотеки, чтобы сам Axolotl работал.
447.83	454.83	Но выглядит это очень здраво, выглядит очень так обнадеживающе.
454.83	455.83	И вроде как...
455.83	456.83	Да.
456.83	464.83	Если получится эту библиотеку использовать, то будет очень-очень быстро все.
464.83	465.83	Надеюсь.
465.83	484.54	Да, это так.
484.54	486.54	Минимально.
486.54	503.16	Да, да.
503.16	527.4	Так...
527.4	529.4	Уф.
529.4	534.4	Вообще изначально можно все сделать в PyTorch.
534.4	538.4	И это, наверное, не суперсложно.
538.4	547.4	Сложности возникают по тому, что это занимает много времени.
547.4	554.4	Это занимает много времени, прежде всего, на валидацию кода.
554.4	557.4	Очень большой объем кода придется написать.
557.4	567.4	Кто бы что ни говорил, но вот нужно будет везде вставлять какие-то удобные функции для отчетов.
567.4	584.4	Чтобы мы потом могли смотреть на то, как у нас растет, например, какая-то метрика, чтобы мы могли за этим следить в интернете.
584.4	595.4	Это тривиально кажется на каких-то игрушечных примерах, но потом на практике очень сильно это загрязняет код.
595.4	612.4	И изначально у нас есть PyTorch, потом над этим Hugging Face, который предоставляет как раз-таки какой-то тренер, какую-то систему для тренировки.
612.4	624.4	Потому что они уже в Hugging Face справляются с мульти... с несколькими графическими картами.
624.4	638.4	И с различными такими тонкостями, которые достаточно сложно проверять самостоятельно.
638.4	653.4	У меня был предмет о диалоговых системах, и там мы имплементировали примерно все вот как бы в PyTorch, ничего больше не использовали.
654.4	668.4	И у нас это как бы заняло целый семестр, такой достаточно несложный... несложный сетап для тренировки у нас занял семестр.
668.4	676.4	И было это разбито на какие-то, опять же, части, которые были уже кем-то наимплементированы и были кем-то уже валидированы.
676.4	682.4	Поэтому мы, опять же, просто написали, и нам кто-то сказал, правильно мы сделали или нет.
682.4	684.4	А когда такого...
684.4	691.4	Фидбэка, когда такого нет, очень сложно понять, если что-то правильно имплементировано или нет.
691.4	708.4	И, соответственно, библиотеки, которые уже предоставляют большой функционал, а потом вот над Hugging Face, ну, или скорее Axolotl напрямую над PyTorch, это там все достаточно как бы флюидно,
708.4	712.4	то они сразу предоставляют поддержку.
712.4	713.4	Скорее всего, уже хардкор.
714.4	716.4	Хорошо наимплементированную.
716.4	718.4	Различных типов.
718.4	720.4	Различных сетапов.
720.4	734.4	Просто даже поддерживают какой-то формат датасетов, для которого процесс тренировки уже более-менее оптимизирован.
734.4	736.4	Ну, что имеется в виду?
736.4	737.4	Какие-то...
737.4	742.4	Если там короткие секвенции, например, 512 токенов, то он его...
742.4	746.4	Будет использоваться так называемый пэкинг.
746.4	751.4	И, соответственно, это тоже имплементировать достаточно непросто.
751.4	753.4	И я вот...
753.4	760.4	На предмете в предыдущем семестре мы делали вот как раз-таки этот...
760.4	769.4	Ну, не то чтобы пэкинг, но мы тоже играли с тем, как мы тренируем модель.
769.4	770.4	И там нужно было правильно...
770.4	773.4	Нужно было правильно подбирать маски.
773.4	777.4	И правильно во время...
777.4	787.4	Во время тренировки сразу, как только мы получаем какой-то ответ от модели, мы его должны прогонять через маску.
787.4	789.4	И было все это очень сложно.
789.4	793.4	Это несколько дней действительно на одну функцию.
793.4	798.4	И, по крайней мере, использование каких-то уже фреймворков дает гарантию, что...
798.4	799.4	Да.
799.4	800.4	Да.
800.4	803.4	То есть от качества, скорее всего, вот так вот.
803.4	806.4	И дает какой-то уровень контроля уже на...
806.4	813.4	С тем, что нам не нужно снова писать какие-то кучи кода.
813.4	817.4	Которые будут брать все аргументы из нашей конфигурации.
817.4	824.4	А у нас уже есть система, где мы напишем до файла конфигурации то, что мы хотим.
824.4	829.4	Понятно, что не все так прекрасно будет работать.
829.4	836.96	работать не все будет поддержано какие-то наши хотелки какие-то наших кастом вещи они не
836.96	843.64	поддержаны но в любом случае дает какой-то уровень контроля вот такой вот на ну как бы на высоком
843.64	853.22	уровне что можно прийти написать путь к дата сету путь к модели какие-то технические вещи там какой
853.22	863.48	тип какой ранг у лоры и все и как бы оно должно работать и они пытаются гарантировать качество
863.48	1035.77	да я я совершенно согласен и конкретно то что мне скорее нужно играться с данными нежели с самим
1035.77	1041.35	способом тренировки меня привело к тому что наверное наверное
1041.59	1050.05	я склоняюсь к использованию библиотеки которая решает тренировку за меня полностью и и несколько
1050.05	1056.53	то что тренировка происходит на нескольких на нескольких графических картах конечно меня
1056.53	1064.09	тоже это привлекает и я понимаю что вот эта параллелизация может происходить и на уровне
1064.09	1070.93	того что на каждом на каждой графической карте будет один эксперимент и просто мы
1070.93	1071.47	и
1071.59	1084.65	несколько запустим в один момент или же у нас будет в рамках одного эксперимента несколько графических карт у меня такая же дилемма была когда я писал диплом и
1084.65	1093.55	работу когда заканчивал бакалавр но она называется диплом по-русски все равно и
1093.55	1101.29	там там тоже была интересная динамика с несколькими графическими картами и
1101.59	1109.21	я очень долго очень много времени потратил что в конце концов принесло очень крутой
1109.21	1114.45	результат потому что я не мог ничего тренировать на четырех графических
1114.45	1119.67	картах а как только у меня получилось по не знаю нескольких месяцев то есть когда
1119.67	1124.25	у меня уже все и остальные части кода были готовы и когда она у меня начало
1124.25	1125.59	работать я просто за пару дней сделал все эксперименты и я specialists marketing русская технология т463 100%
1125.59	1126.63	я просто за пару дней сделал все эксперименты и я не могу сказать что теперь для нас freedge merеры очень�리кая с IE мы reframe с их головой в числе тех четыре ятсы IE у меня на следующем у меня с риска россий pickled으로 не знаю так я не могу сказать что 밀кет 원кер рендереDD с рекламного уондей No Support White's
1126.63	1142.85	Я просто за пару дней сделал все эксперименты, и я мог оперативно реагировать на результаты и очень быстро запускать новые эксперименты уже с измененными киперпараметрами, с измененными какими-то конфигурациями.
1142.85	1159.39	Поэтому у меня такой опыт, что если я даже потрачу несколько недель на установку чего-либо, но если оно в конце концов будет работать, то это очень сильно поможет.
1161.49	1172.55	Но я понимаю, что нужно уже спешить и какие-то результаты получать.
1172.69	1172.83	Я согласен.
1172.85	1192.85	Я в любом случае, я не буду как-то вычурно тут стараться до конца сидеть и «Ой, я устанавливаю библиотеки», но, конечно, в какой-то момент мне, наверное, придется сдаться и перейти на что-то ближе к сетапу __PERSON2__.
1192.85	1202.55	Но я что хотел проконсультировать-то? Я хотел проконсультировать такое вот изменение в правилах.
1202.85	1215.73	Я хотел проконсультировать, что все тест-сеты будут на уровне абзацев, а не предложений.
1217.11	1227.11	И как мы должны тренировать модель, чтобы это было эффективно и чтобы она действительно умела переводить абзацы.
1227.11	1232.69	Мы с __PERSON2__ поговорили об этом, и он говорит, что можно, в принципе...
1232.85	1252.15	В принципе-то, тренировать на предложениях можно еще как сделать? Можно тренировать на предложениях, но таким способом, что в контекст модели будут добавлены референсы с предыдущих предложений в рамках абзаца.
1253.61	1259.15	И мне показалось это как-то достаточно интуитивным, как вот было на диалоговых системах, что да, нужно предсказать только...
1259.15	1261.15	Да, нужно предсказать только...
1262.85	1271.85	Один ответ сейчас, один ответ системы, но в контексте этой системы уже будет вся ветка диалога.
1273.37	1284.73	И потом еще, наверное, такой вариант, что просто взять реально целый абзац на целый абзац и посмотреть, как это будет работать.
1284.73	1339.27	И...
1512.14	1514.84	Да.
1516.2	1518.64	Полностью согласен, и спасибо за...
1519.3	1519.74	Спасибо.
1519.76	1525.72	Спасибо за подтверждение, что это действительно хорошее направление.
1526.4	1528.3	И у меня вопрос.
1528.84	1538.7	Мы хотим сдавать наши системы на так называемый ограниченный трек, constraint.
1538.7	1548.7	И я посмотрел на доступные датасеты, и в том числе меня интересовало, в каких датасетах...
1548.7	1551.7	В каких датасетах этот контекст сохраняется.
1551.7	1557.7	Я нашел тот же news commentary.
1557.7	1561.7	Europarl.
1561.7	1567.7	Только, по-моему, для русского языка его нет.
1567.7	1569.7	Или... Да, его нет.
1569.7	1575.38	Да.
1575.38	1583.88	Да.
1583.88	1585.88	Да.
1585.88	1587.88	У них наоборот сильно...
1587.88	1588.64	У них наоборот сильно...
1588.64	1591.14	Отторжение русского языка происходит.
1591.14	1592.14	Я просто...
1592.14	1594.64	Я просто думал, что кто-то возьмет...
1594.64	1603.14	И реально прям зааннотирует все вот эти вот датасеты во всех языках, но нет, к сожалению.
1603.14	1605.64	И, соответственно, в том же...
1605.64	1611.14	Вот если взять news commentary, то там нет разделения на абзацы.
1611.14	1615.64	Там есть как бы статьи, и они лежат вместе.
1615.64	1618.54	Как бы чанки лежат вместе.
1618.64	1630.58	Но вот эти границы, да, и поэтому я думаю, может реально взять какие-то чанки по 10-15 предложений, например.
1634.22	1634.54	Окей.
1684.54	1688.28	И хорошо, это теперь мне тоже понятно.
1688.28	1707.28	И потом еще вот такая вот немного проблема, что когда мы берем по предложениям, мы действительно можем очень сократить длину самих тренировочных примеров.
1707.28	1717.68	А когда мы берем абзацы, то действительно там очень много этих данных, и там, например, нужно брать максимальную длину 2048.
1718.28	1734.08	И уже достаточно сложно это идет и на сетапе __PERSON2__, что длинные секвенции просто сложнее, ну то есть дольше обрабатываются.
1734.08	1737.58	В плане дольше на них тренируется модель.
1738.38	1755.53	И не говорю, что он как-то лимитирован.
1755.71	1763.71	Скорее, что на его сетапе тренировка абзацев очень медленная.
1764.71	1777.28	Да, и вот. Окей.
1779.5	1779.86	Окей.
1821.07	1830.79	К сожалению, я, наверное, не смогу написать все нормально, потому что я вас понимаю, я чешский понимаю, поэтому у меня байос в любом случае.
1833.81	1835.13	Окей, окей.
1835.31	1843.92	Спасибо вам. Все. До свидания.
